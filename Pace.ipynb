{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJoIJL/+SFV75SplS8XG7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gcoles22/GCs-Room-Proposer/blob/main/Pace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V13): MULTI-FILE INGESTION, CLEANING, AND ANALYSIS ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "# --- COMMON FUNCTIONS (Defined once) ---\n",
        "\n",
        "# 1. Function to clean money values (removes '$', ',', converts to float)\n",
        "def clean_money(value):\n",
        "    if pd.isna(value):\n",
        "        return 0.0\n",
        "    clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "    try:\n",
        "        return float(clean_val)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "# 2. Function to standardize supplier names (specifically for Big 4)\n",
        "def clean_supplier_name(name):\n",
        "    if pd.isna(name):\n",
        "        return \"UNKNOWN\" # Placeholder for missing names\n",
        "\n",
        "    name_str = str(name).upper()\n",
        "\n",
        "    if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "        return 'PwC (Consolidated)'\n",
        "    elif 'DELOITTE' in name_str:\n",
        "        return 'Deloitte (Consolidated)'\n",
        "    elif 'ERNST & YOUNG' in name_str or 'EY' in name_str:\n",
        "        return 'EY (Consolidated)'\n",
        "    elif 'KPMG' in name_str:\n",
        "        return 'KPMG (Consolidated)'\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "# --- MULTI-FILE INGESTION PROCESS ---\n",
        "\n",
        "# Define the list of files you want to process\n",
        "file_names = [\n",
        "    'pwc_pace_data.csv',\n",
        "    'deloitte_pace_data.csv',\n",
        "    'kpmg_pace_data.csv',\n",
        "    'ey_pace_data.csv'\n",
        "]\n",
        "\n",
        "all_processed_dfs = [] # This list will hold each cleaned DataFrame\n",
        "\n",
        "print(\"--- Starting Multi-File Ingestion ---\")\n",
        "\n",
        "for file_name in file_names:\n",
        "    print(f\"\\nProcessing file: {file_name}...\")\n",
        "    temp_df = None # Initialize temp_df\n",
        "    try:\n",
        "        # Try UTF-8 first\n",
        "        temp_df = pd.read_csv(file_name, encoding='utf-8', skiprows=16, header=None)\n",
        "        print(\"  Attempted UTF-8 encoding.\")\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            # If UTF-8 fails, try Latin-1\n",
        "            temp_df = pd.read_csv(file_name, encoding='latin-1', skiprows=16, header=None)\n",
        "            print(\"  UTF-8 failed, successfully tried Latin-1 encoding.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: Could not read '{file_name}' with UTF-8 or Latin-1: {e}\")\n",
        "            continue # Skip to next file if both fail\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: File '{file_name}' not found. Please upload it to Colab.\")\n",
        "        continue # Skip to next file\n",
        "\n",
        "    if temp_df is not None:\n",
        "        try:\n",
        "            # Manually set headers from the second row (index 1) of the raw loaded data\n",
        "            temp_df.columns = temp_df.iloc[1]\n",
        "\n",
        "            # Drop the first two rows (the NaN row and the header row)\n",
        "            temp_df = temp_df[2:].reset_index(drop=True)\n",
        "\n",
        "            print(f\"‚úÖ Success! Data loaded and headers assigned from {file_name}.\")\n",
        "\n",
        "            # Apply cleaning functions\n",
        "            temp_df['Clean_Supplier'] = temp_df['Supplier Name'].apply(clean_supplier_name)\n",
        "            if 'Value (AUD)' in temp_df.columns:\n",
        "                temp_df['Clean_Value'] = temp_df['Value (AUD)'].apply(clean_money)\n",
        "            else:\n",
        "                print(f\"‚ùå 'Value (AUD)' column not found in {file_name}. Assigning 0.0.\")\n",
        "                temp_df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "            all_processed_dfs.append(temp_df)\n",
        "            print(f\"  Rows loaded and cleaned: {len(temp_df)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing data structure in '{file_name}': {e}\")\n",
        "\n",
        "\n",
        "# --- CONSOLIDATION AND DEDUPLICATION ---\n",
        "\n",
        "if all_processed_dfs:\n",
        "    df = pd.concat(all_processed_dfs, ignore_index=True)\n",
        "    print(f\"\\n--- All files concatenated. Initial total rows: {len(df)} ---\")\n",
        "\n",
        "    # Remove duplicate contracts based on 'CN ID' (Contract Notice ID)\n",
        "    original_rows = len(df)\n",
        "    if 'CN ID' in df.columns:\n",
        "        df.drop_duplicates(subset=['CN ID'], keep='first', inplace=True)\n",
        "        deduplicated_rows = len(df)\n",
        "        print(f\"--- Deduplicated {original_rows - deduplicated_rows} rows. Remaining unique contracts: {deduplicated_rows} ---\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è 'CN ID' column not found for deduplication. Skipping deduplication.\")\n",
        "        deduplicated_rows = original_rows\n",
        "\n",
        "    print(\"\\n‚úÖ Final Consolidated Data loaded for analysis.\")\n",
        "    print(f\"Total unique contracts: {deduplicated_rows}\")\n",
        "    print(\"Columns in final DataFrame:\", list(df.columns))\n",
        "    print(\"First 5 rows of consolidated data:\")\n",
        "    print(df.head())\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå No data frames were successfully processed. PACE engine cannot proceed.\")\n",
        "    raise SystemExit(\"No data loaded to process.\")\n",
        "\n",
        "# --- PACE MODULE 2: CORE ANALYSIS ---\n",
        "\n",
        "# Ensure Clean_Value is numeric (important for sum operations later)\n",
        "df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "\n",
        "# Analysis A: Total Spend by the Consolidated Big 4 Entities\n",
        "# Define the Big 4 firms for consolidated reporting\n",
        "big_4_firms = [\n",
        "    'PwC (Consolidated)',\n",
        "    'Deloitte (Consolidated)',\n",
        "    'EY (Consolidated)',\n",
        "    'KPMG (Consolidated)'\n",
        "]\n",
        "\n",
        "# Analysis B: The \"Vague Description\" Hunter (now smarter!)\n",
        "vague_keywords = [\n",
        "    'management advisory services', 'consulting service', 'strategic advice',\n",
        "    'professional services', 'advisory services', 'business advisory services',\n",
        "    'support services', 'review services', 'quality assurance',\n",
        "    'advisory support', 'program management', 'capacity building',\n",
        "    'evaluation services', 'transformation services', 'change management'\n",
        "]\n",
        "\n",
        "vague_pattern = '|'.join(vague_keywords)\n",
        "keyword_vague_data = df[\n",
        "    df['Title'].fillna('').str.lower().str.contains(vague_pattern, na=False)\n",
        "]\n",
        "\n",
        "short_titles_data = df[\n",
        "    df['Title'].fillna('').apply(lambda x: len(str(x).split())) < 4\n",
        "]\n",
        "\n",
        "vague_data = pd.concat([keyword_vague_data, short_titles_data]).drop_duplicates(subset=['CN ID'])\n",
        "\n",
        "total_vague = vague_data['Clean_Value'].sum()\n",
        "vague_count = len(vague_data)\n",
        "\n",
        "\n",
        "# Analysis C: The \"Just Under Threshold\" Hunter\n",
        "threshold_min = 70000.00\n",
        "threshold_max = 79999.99\n",
        "\n",
        "just_under_threshold_data = df[\n",
        "    (df['Clean_Value'] >= threshold_min) &\n",
        "    (df['Clean_Value'] <= threshold_max)\n",
        "]\n",
        "total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "# Analysis D: The \"Super Red Flag\" Hunter (Vague AND Just Under Threshold)\n",
        "super_red_flag_data = pd.merge(\n",
        "    vague_data[['CN ID', 'Clean_Value']],\n",
        "    just_under_threshold_data[['CN ID', 'Clean_Value']],\n",
        "    on='CN ID',\n",
        "    how='inner'\n",
        ")\n",
        "super_red_flag_count = len(super_red_flag_data)\n",
        "super_red_flag_total = super_red_flag_data['Clean_Value_x'].sum()\n",
        "\n",
        "\n",
        "# --- PACE MODULE 3: REPORTING ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"      PACE ENGINE - CONSOLIDATED REPORT      \")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Report for each of the Big 4 firms\n",
        "total_big_4_spend = 0\n",
        "for firm in big_4_firms:\n",
        "    firm_data = df[df['Clean_Supplier'] == firm]\n",
        "    firm_spend = firm_data['Clean_Value'].sum()\n",
        "    total_big_4_spend += firm_spend\n",
        "    if firm_spend > 0: # Only print if there was actual spend found for the firm\n",
        "        print(f\"üí∞ Total Spend with {firm:<22}: ${firm_spend:,.2f}\")\n",
        "\n",
        "print(f\"\\nüìà Grand Total Big 4 Spend (in this data): ${total_big_4_spend:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "print(f\"üö® Super Red Flag (Vague & Under Threshold): {super_red_flag_count}\")\n",
        "print(f\"üí≤ Value of Super Red Flag Contracts: ${super_red_flag_total:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# --- Sample Outputs for each category ---\n",
        "\n",
        "print(\"\\n--- Sample of Vague Contracts Found: ---\")\n",
        "if not vague_data.empty:\n",
        "    original_vague_contracts = df[df['CN ID'].isin(vague_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_vague_contracts.columns]\n",
        "    print(original_vague_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Just Under Threshold' Contracts Found: ---\")\n",
        "if not just_under_threshold_data.empty:\n",
        "    original_threshold_contracts = df[df['CN ID'].isin(just_under_threshold_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_threshold_contracts.columns]\n",
        "    print(original_threshold_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Super Red Flag' Contracts Found: ---\")\n",
        "if not super_red_flag_data.empty:\n",
        "    original_super_red_flags = df[df['CN ID'].isin(super_red_flag_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_super_red_flags.columns]\n",
        "    print(original_super_red_flags[actual_display_cols].head())\n",
        "else:\n",
        "    print(\"No 'Super Red Flag' contracts found in this sample.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTLEWn707bma",
        "outputId": "db7f6dcb-fde0-4828-938f-4e4b73a4cd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-File Ingestion ---\n",
            "\n",
            "Processing file: pwc_pace_data.csv...\n",
            "  Attempted UTF-8 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from pwc_pace_data.csv.\n",
            "  Rows loaded and cleaned: 155\n",
            "\n",
            "Processing file: deloitte_pace_data.csv...\n",
            "  UTF-8 failed, successfully tried Latin-1 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from deloitte_pace_data.csv.\n",
            "  Rows loaded and cleaned: 3298\n",
            "\n",
            "Processing file: kpmg_pace_data.csv...\n",
            "  UTF-8 failed, successfully tried Latin-1 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from kpmg_pace_data.csv.\n",
            "  Rows loaded and cleaned: 4977\n",
            "\n",
            "Processing file: ey_pace_data.csv...\n",
            "  Attempted UTF-8 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from ey_pace_data.csv.\n",
            "  Rows loaded and cleaned: 72\n",
            "\n",
            "--- All files concatenated. Initial total rows: 8502 ---\n",
            "--- Deduplicated 0 rows. Remaining unique contracts: 8502 ---\n",
            "\n",
            "‚úÖ Final Consolidated Data loaded for analysis.\n",
            "Total unique contracts: 8502\n",
            "Columns in final DataFrame: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan), 'Clean_Supplier', 'Clean_Value']\n",
            "First 5 rows of consolidated data:\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \\\n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN   \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN   \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN   \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN   \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN   \n",
            "\n",
            "1      Clean_Supplier  Clean_Value  \n",
            "0  PwC (Consolidated)     26500.00  \n",
            "1  PwC (Consolidated)    163900.00  \n",
            "2  PwC (Consolidated)    770000.00  \n",
            "3  PwC (Consolidated)    179502.19  \n",
            "4  PwC (Consolidated)     26500.00  \n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - CONSOLIDATED REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated)    : $202,578,938.13\n",
            "üí∞ Total Spend with Deloitte (Consolidated): $2,039,298,634.79\n",
            "üí∞ Total Spend with EY (Consolidated)     : $21,504,854.69\n",
            "üí∞ Total Spend with KPMG (Consolidated)   : $3,121,997,494.11\n",
            "\n",
            "üìà Grand Total Big 4 Spend (in this data): $5,385,379,921.72\n",
            "========================================\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   4328\n",
            "üí∏ Total Value of Vague Contracts:      $3,430,582,663.44\n",
            "üìâ Contracts Just Under $80k Threshold: 488\n",
            "üíµ Value of Just Under Threshold Contracts: $37,141,186.83\n",
            "üö® Super Red Flag (Vague & Under Threshold): 234\n",
            "üí≤ Value of Super Red Flag Contracts: $17,819,420.16\n",
            "========================================\n",
            "\n",
            "--- Sample of Vague Contracts Found: ---\n",
            "1                                             Agency  \\\n",
            "0  Department of Infrastructure, Transport, Regio...   \n",
            "4  Department of Infrastructure, Transport, Regio...   \n",
            "6                     Australian Signals Directorate   \n",
            "7  Office of the Official Secretary to the Govern...   \n",
            "8                              Department of Defence   \n",
            "\n",
            "1                         Title Value (AUD)  \\\n",
            "0     Data Subscription Service   26,500.00   \n",
            "4        Media Outlook Services   26,500.00   \n",
            "6           Soundproofing Works   13,241.42   \n",
            "7  Management advisory services   75,000.00   \n",
            "8   Leadership Pathway Training   35,200.00   \n",
            "\n",
            "1                                      Supplier Name  \n",
            "0                         PWC PRODUCT SALES LLC (US)  \n",
            "4                         PwC Product Sales LLC (US)  \n",
            "6                                 PWC PROPERTY WORKS  \n",
            "7  PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "8                         PWC CONSULTING PTY LIMITED  \n",
            "\n",
            "--- Sample of 'Just Under Threshold' Contracts Found: ---\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \\\n",
            "7      Management advisory services   75,000.00   \n",
            "13  Data Workforce Plan Development   75,542.00   \n",
            "22               Accounting Support   79,092.00   \n",
            "49              WFP Special Project   75,000.00   \n",
            "77                Quality Framework   78,810.00   \n",
            "\n",
            "1                                       Supplier Name  \n",
            "7   PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "13                                                PWC  \n",
            "22                                                PwC  \n",
            "49                         PwC Consulting (Australia)  \n",
            "77                  PwC Strategy& (Australia) Pty Ltd  \n",
            "\n",
            "--- Sample of 'Super Red Flag' Contracts Found: ---\n",
            "1                                               Agency  \\\n",
            "7    Office of the Official Secretary to the Govern...   \n",
            "22   Office of the Official Secretary to the Govern...   \n",
            "49                       Attorney-General's Department   \n",
            "77                                  Services Australia   \n",
            "112                              Department of Defence   \n",
            "\n",
            "1                           Title Value (AUD)  \\\n",
            "7    Management advisory services   75,000.00   \n",
            "22             Accounting Support   79,092.00   \n",
            "49            WFP Special Project   75,000.00   \n",
            "77              Quality Framework   78,810.00   \n",
            "112           Contractor Services   75,612.50   \n",
            "\n",
            "1                                        Supplier Name  \n",
            "7    PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "22                                                 PwC  \n",
            "49                          PwC Consulting (Australia)  \n",
            "77                   PwC Strategy& (Australia) Pty Ltd  \n",
            "112                    PWC STRATEGY&(AUSTRALIA)PTY LTD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mWPk0hXV7bVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V13): MULTI-FILE INGESTION, CLEANING, AND ANALYSIS ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "# --- COMMON FUNCTIONS (Defined once) ---\n",
        "\n",
        "# 1. Function to clean money values (removes '$', ',', converts to float)\n",
        "def clean_money(value):\n",
        "    if pd.isna(value):\n",
        "        return 0.0\n",
        "    clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "    try:\n",
        "        return float(clean_val)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "# 2. Function to standardize supplier names (specifically for Big 4)\n",
        "def clean_supplier_name(name):\n",
        "    if pd.isna(name):\n",
        "        return \"UNKNOWN\" # Placeholder for missing names\n",
        "\n",
        "    name_str = str(name).upper()\n",
        "\n",
        "    if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "        return 'PwC (Consolidated)'\n",
        "    elif 'DELOITTE' in name_str:\n",
        "        return 'Deloitte (Consolidated)'\n",
        "    elif 'ERNST & YOUNG' in name_str or 'EY' in name_str:\n",
        "        return 'EY (Consolidated)'\n",
        "    elif 'KPMG' in name_str:\n",
        "        return 'KPMG (Consolidated)'\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "# --- MULTI-FILE INGESTION PROCESS ---\n",
        "\n",
        "# Define the list of files you want to process\n",
        "file_names = [\n",
        "    'pwc_pace_data.csv',\n",
        "    'deloitte_pace_data.csv',\n",
        "    'kmpg_pace_data.csv', # Corrected typo kmpg -> kpmg if it was there in file_names list\n",
        "    'ey_pace_data.csv'\n",
        "]\n",
        "\n",
        "all_processed_dfs = [] # This list will hold each cleaned DataFrame\n",
        "\n",
        "print(\"--- Starting Multi-File Ingestion ---\")\n",
        "\n",
        "for file_name in file_names:\n",
        "    print(f\"\\nProcessing file: {file_name}...\")\n",
        "    temp_df = None # Initialize temp_df\n",
        "    try:\n",
        "        # Try UTF-8 first\n",
        "        temp_df = pd.read_csv(file_name, encoding='utf-8', skiprows=16, header=None)\n",
        "        print(\"  Attempted UTF-8 encoding.\")\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            # If UTF-8 fails, try Latin-1\n",
        "            temp_df = pd.read_csv(file_name, encoding='latin-1', skiprows=16, header=None)\n",
        "            print(\"  UTF-8 failed, successfully tried Latin-1 encoding.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: Could not read '{file_name}' with UTF-8 or Latin-1: {e}\")\n",
        "            continue # Skip to next file if both fail\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: File '{file_name}' not found. Please upload it to Colab.\")\n",
        "        continue # Skip to next file\n",
        "\n",
        "    if temp_df is not None:\n",
        "        try:\n",
        "            # Manually set headers from the second row (index 1) of the raw loaded data\n",
        "            temp_df.columns = temp_df.iloc[1]\n",
        "\n",
        "            # Drop the first two rows (the NaN row and the header row)\n",
        "            temp_df = temp_df[2:].reset_index(drop=True)\n",
        "\n",
        "            print(f\"‚úÖ Success! Data loaded and headers assigned from {file_name}.\")\n",
        "\n",
        "            # Apply cleaning functions\n",
        "            temp_df['Clean_Supplier'] = temp_df['Supplier Name'].apply(clean_supplier_name)\n",
        "            if 'Value (AUD)' in temp_df.columns:\n",
        "                temp_df['Clean_Value'] = temp_df['Value (AUD)'].apply(clean_money)\n",
        "            else:\n",
        "                print(f\"‚ùå 'Value (AUD)' column not found in {file_name}. Assigning 0.0.\")\n",
        "                temp_df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "            all_processed_dfs.append(temp_df)\n",
        "            print(f\"  Rows loaded and cleaned: {len(temp_df)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing data structure in '{file_name}': {e}\")\n",
        "\n",
        "\n",
        "# --- CONSOLIDATION AND DEDUPLICATION ---\n",
        "\n",
        "if all_processed_dfs:\n",
        "    df = pd.concat(all_processed_dfs, ignore_index=True)\n",
        "    print(f\"\\n--- All files concatenated. Initial total rows: {len(df)} ---\")\n",
        "\n",
        "    # Remove duplicate contracts based on 'CN ID' (Contract Notice ID)\n",
        "    original_rows = len(df)\n",
        "    if 'CN ID' in df.columns:\n",
        "        df.drop_duplicates(subset=['CN ID'], keep='first', inplace=True)\n",
        "        deduplicated_rows = len(df)\n",
        "        print(f\"--- Deduplicated {original_rows - deduplicated_rows} rows. Remaining unique contracts: {deduplicated_rows} ---\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è 'CN ID' column not found for deduplication. Skipping deduplication.\")\n",
        "        deduplicated_rows = original_rows\n",
        "\n",
        "    print(\"\\n‚úÖ Final Consolidated Data loaded for analysis.\")\n",
        "    print(f\"Total unique contracts: {deduplicated_rows}\")\n",
        "    print(\"Columns in final DataFrame:\", list(df.columns))\n",
        "    print(\"First 5 rows of consolidated data:\")\n",
        "    print(df.head())\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå No data frames were successfully processed. PACE engine cannot proceed.\")\n",
        "    raise SystemExit(\"No data loaded to process.\")\n",
        "\n",
        "# --- PACE MODULE 2: CORE ANALYSIS ---\n",
        "\n",
        "# Ensure Clean_Value is numeric (important for sum operations later)\n",
        "df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "\n",
        "# Analysis A: Total Spend by the Consolidated Big 4 Entities\n",
        "# Define the Big 4 firms for consolidated reporting\n",
        "big_4_firms = [\n",
        "    'PwC (Consolidated)',\n",
        "    'Deloitte (Consolidated)',\n",
        "    'EY (Consolidated)',\n",
        "    'KPMG (Consolidated)'\n",
        "]\n",
        "\n",
        "# Analysis B: The \"Vague Description\" Hunter (now smarter!)\n",
        "vague_keywords = [\n",
        "    'management advisory services', 'consulting service', 'strategic advice',\n",
        "    'professional services', 'advisory services', 'business advisory services',\n",
        "    'support services', 'review services', 'quality assurance',\n",
        "    'advisory support', 'program management', 'capacity building',\n",
        "    'evaluation services', 'transformation services', 'change management'\n",
        "]\n",
        "\n",
        "vague_pattern = '|'.join(vague_keywords)\n",
        "keyword_vague_data = df[\n",
        "    df['Title'].fillna('').str.lower().str.contains(vague_pattern, na=False)\n",
        "]\n",
        "\n",
        "short_titles_data = df[\n",
        "    df['Title'].fillna('').apply(lambda x: len(str(x).split())) < 4\n",
        "]\n",
        "\n",
        "vague_data = pd.concat([keyword_vague_data, short_titles_data]).drop_duplicates(subset=['CN ID'])\n",
        "\n",
        "total_vague = vague_data['Clean_Value'].sum()\n",
        "vague_count = len(vague_data)\n",
        "\n",
        "\n",
        "# Analysis C: The \"Just Under Threshold\" Hunter\n",
        "threshold_min = 70000.00\n",
        "threshold_max = 79999.99\n",
        "\n",
        "just_under_threshold_data = df[\n",
        "    (df['Clean_Value'] >= threshold_min) &\n",
        "    (df['Clean_Value'] <= threshold_max)\n",
        "]\n",
        "total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "# Analysis D: The \"Super Red Flag\" Hunter (Vague AND Just Under Threshold)\n",
        "super_red_flag_data = pd.merge(\n",
        "    vague_data[['CN ID', 'Clean_Value']],\n",
        "    just_under_threshold_data[['CN ID', 'Clean_Value']],\n",
        "    on='CN ID',\n",
        "    how='inner'\n",
        ")\n",
        "super_red_flag_count = len(super_red_flag_data)\n",
        "super_red_flag_total = super_red_flag_data['Clean_Value_x'].sum()\n",
        "\n",
        "\n",
        "# --- PACE MODULE 3: REPORTING ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"      PACE ENGINE - CONSOLIDATED REPORT      \")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Report for each of the Big 4 firms\n",
        "total_big_4_spend = 0\n",
        "for firm in big_4_firms:\n",
        "    firm_data = df[df['Clean_Supplier'] == firm]\n",
        "    firm_spend = firm_data['Clean_Value'].sum()\n",
        "    total_big_4_spend += firm_spend\n",
        "    if firm_spend > 0: # Only print if there was actual spend found for the firm\n",
        "        print(f\"üí∞ Total Spend with {firm:<22}: ${firm_spend:,.2f}\")\n",
        "\n",
        "print(f\"\\nüìà Grand Total Big 4 Spend (in this data): ${total_big_4_spend:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "print(f\"üö® Super Red Flag (Vague & Under Threshold): {super_red_flag_count}\")\n",
        "print(f\"üí≤ Value of Super Red Flag Contracts: ${super_red_flag_total:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# --- Sample Outputs for each category ---\n",
        "\n",
        "print(\"\\n--- Sample of Vague Contracts Found: ---\")\n",
        "if not vague_data.empty:\n",
        "    original_vague_contracts = df[df['CN ID'].isin(vague_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_vague_contracts.columns]\n",
        "    print(original_vague_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Just Under Threshold' Contracts Found: ---\")\n",
        "if not just_under_threshold_data.empty:\n",
        "    original_threshold_contracts = df[df['CN ID'].isin(just_under_threshold_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_threshold_contracts.columns]\n",
        "    print(original_threshold_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Super Red Flag' Contracts Found: ---\")\n",
        "if not super_red_flag_data.empty:\n",
        "    original_super_red_flags = df[df['CN ID'].isin(super_red_flag_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name']\n",
        "    actual_display_cols = [col for col in display_cols if col in original_super_red_flags.columns]\n",
        "    print(original_super_red_flags[actual_display_cols].head())\n",
        "else:\n",
        "    print(\"No 'Super Red Flag' contracts found in this sample.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-sCWC6h6__7",
        "outputId": "4bb42aff-ce89-4901-ac43-c87a957594b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-File Ingestion ---\n",
            "\n",
            "Processing file: pwc_pace_data.csv...\n",
            "  Attempted UTF-8 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from pwc_pace_data.csv.\n",
            "  Rows loaded and cleaned: 155\n",
            "\n",
            "Processing file: deloitte_pace_data.csv...\n",
            "  UTF-8 failed, successfully tried Latin-1 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from deloitte_pace_data.csv.\n",
            "  Rows loaded and cleaned: 3298\n",
            "\n",
            "Processing file: kmpg_pace_data.csv...\n",
            "‚ùå Error: File 'kmpg_pace_data.csv' not found. Please upload it to Colab.\n",
            "\n",
            "Processing file: ey_pace_data.csv...\n",
            "  Attempted UTF-8 encoding.\n",
            "‚úÖ Success! Data loaded and headers assigned from ey_pace_data.csv.\n",
            "  Rows loaded and cleaned: 72\n",
            "\n",
            "--- All files concatenated. Initial total rows: 3525 ---\n",
            "--- Deduplicated 0 rows. Remaining unique contracts: 3525 ---\n",
            "\n",
            "‚úÖ Final Consolidated Data loaded for analysis.\n",
            "Total unique contracts: 3525\n",
            "Columns in final DataFrame: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan), 'Clean_Supplier', 'Clean_Value']\n",
            "First 5 rows of consolidated data:\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \\\n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN   \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN   \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN   \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN   \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN   \n",
            "\n",
            "1      Clean_Supplier  Clean_Value  \n",
            "0  PwC (Consolidated)     26500.00  \n",
            "1  PwC (Consolidated)    163900.00  \n",
            "2  PwC (Consolidated)    770000.00  \n",
            "3  PwC (Consolidated)    179502.19  \n",
            "4  PwC (Consolidated)     26500.00  \n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - CONSOLIDATED REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated)    : $202,578,938.13\n",
            "üí∞ Total Spend with Deloitte (Consolidated): $2,039,298,634.79\n",
            "üí∞ Total Spend with EY (Consolidated)     : $20,892,038.69\n",
            "\n",
            "üìà Grand Total Big 4 Spend (in this data): $2,262,769,611.61\n",
            "========================================\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   1723\n",
            "üí∏ Total Value of Vague Contracts:      $1,301,835,120.05\n",
            "üìâ Contracts Just Under $80k Threshold: 214\n",
            "üíµ Value of Just Under Threshold Contracts: $16,367,222.69\n",
            "üö® Super Red Flag (Vague & Under Threshold): 94\n",
            "üí≤ Value of Super Red Flag Contracts: $7,188,061.11\n",
            "========================================\n",
            "\n",
            "--- Sample of Vague Contracts Found: ---\n",
            "1                                             Agency  \\\n",
            "0  Department of Infrastructure, Transport, Regio...   \n",
            "4  Department of Infrastructure, Transport, Regio...   \n",
            "6                     Australian Signals Directorate   \n",
            "7  Office of the Official Secretary to the Govern...   \n",
            "8                              Department of Defence   \n",
            "\n",
            "1                         Title Value (AUD)  \\\n",
            "0     Data Subscription Service   26,500.00   \n",
            "4        Media Outlook Services   26,500.00   \n",
            "6           Soundproofing Works   13,241.42   \n",
            "7  Management advisory services   75,000.00   \n",
            "8   Leadership Pathway Training   35,200.00   \n",
            "\n",
            "1                                      Supplier Name  \n",
            "0                         PWC PRODUCT SALES LLC (US)  \n",
            "4                         PwC Product Sales LLC (US)  \n",
            "6                                 PWC PROPERTY WORKS  \n",
            "7  PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "8                         PWC CONSULTING PTY LIMITED  \n",
            "\n",
            "--- Sample of 'Just Under Threshold' Contracts Found: ---\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \\\n",
            "7      Management advisory services   75,000.00   \n",
            "13  Data Workforce Plan Development   75,542.00   \n",
            "22               Accounting Support   79,092.00   \n",
            "49              WFP Special Project   75,000.00   \n",
            "77                Quality Framework   78,810.00   \n",
            "\n",
            "1                                       Supplier Name  \n",
            "7   PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "13                                                PWC  \n",
            "22                                                PwC  \n",
            "49                         PwC Consulting (Australia)  \n",
            "77                  PwC Strategy& (Australia) Pty Ltd  \n",
            "\n",
            "--- Sample of 'Super Red Flag' Contracts Found: ---\n",
            "1                                               Agency  \\\n",
            "7    Office of the Official Secretary to the Govern...   \n",
            "22   Office of the Official Secretary to the Govern...   \n",
            "49                       Attorney-General's Department   \n",
            "77                                  Services Australia   \n",
            "112                              Department of Defence   \n",
            "\n",
            "1                           Title Value (AUD)  \\\n",
            "7    Management advisory services   75,000.00   \n",
            "22             Accounting Support   79,092.00   \n",
            "49            WFP Special Project   75,000.00   \n",
            "77              Quality Framework   78,810.00   \n",
            "112           Contractor Services   75,612.50   \n",
            "\n",
            "1                                        Supplier Name  \n",
            "7    PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "22                                                 PwC  \n",
            "49                          PwC Consulting (Australia)  \n",
            "77                   PwC Strategy& (Australia) Pty Ltd  \n",
            "112                    PWC STRATEGY&(AUSTRALIA)PTY LTD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V12): MULTI-FILE INGESTION, CLEANING, AND ANALYSIS ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "# --- COMMON FUNCTIONS (Defined once) ---\n",
        "\n",
        "# 1. Function to clean money values (removes '$', ',', converts to float)\n",
        "def clean_money(value):\n",
        "    if pd.isna(value):\n",
        "        return 0.0\n",
        "    clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "    try:\n",
        "        return float(clean_val)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "# 2. Function to standardize supplier names (specifically for Big 4)\n",
        "def clean_supplier_name(name):\n",
        "    if pd.isna(name):\n",
        "        return \"UNKNOWN\" # Placeholder for missing names\n",
        "\n",
        "    name_str = str(name).upper()\n",
        "\n",
        "    if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "        return 'PwC (Consolidated)'\n",
        "    elif 'DELOITTE' in name_str:\n",
        "        return 'Deloitte (Consolidated)'\n",
        "    elif 'ERNST & YOUNG' in name_str or 'EY' in name_str:\n",
        "        return 'EY (Consolidated)'\n",
        "    elif 'KPMG' in name_str:\n",
        "        return 'KPMG (Consolidated)'\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "# --- MULTI-FILE INGESTION PROCESS ---\n",
        "\n",
        "# Define the list of files you want to process\n",
        "file_names = [\n",
        "    'pwc_pace_data.csv',\n",
        "    'deloitte_pace_data.csv',\n",
        "    'kpmg_pace_data.csv',\n",
        "    'ey_pace_data.csv'\n",
        "]\n",
        "\n",
        "all_processed_dfs = [] # This list will hold each cleaned DataFrame\n",
        "\n",
        "print(\"--- Starting Multi-File Ingestion ---\")\n",
        "\n",
        "for file_name in file_names:\n",
        "    print(f\"\\nProcessing file: {file_name}...\")\n",
        "    try:\n",
        "        # Load the data: skiprows=16, header=None to handle AusTender's format\n",
        "        temp_df = pd.read_csv(file_name, encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "        # Manually set headers from the second row (index 1) of the raw loaded data\n",
        "        temp_df.columns = temp_df.iloc[1]\n",
        "\n",
        "        # Drop the first two rows (the NaN row and the header row)\n",
        "        temp_df = temp_df[2:].reset_index(drop=True)\n",
        "\n",
        "        print(f\"‚úÖ Success! Data loaded and headers assigned from {file_name}.\")\n",
        "\n",
        "        # Apply cleaning functions\n",
        "        temp_df['Clean_Supplier'] = temp_df['Supplier Name'].apply(clean_supplier_name)\n",
        "        if 'Value (AUD)' in temp_df.columns:\n",
        "            temp_df['Clean_Value'] = temp_df['Value (AUD)'].apply(clean_money)\n",
        "        else:\n",
        "            print(f\"‚ùå 'Value (AUD)' column not found in {file_name}. Assigning 0.0.\")\n",
        "            temp_df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "        all_processed_dfs.append(temp_df)\n",
        "        print(f\"  Rows loaded and cleaned: {len(temp_df)}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: File '{file_name}' not found. Please upload it to Colab.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing '{file_name}': {e}\")\n",
        "\n",
        "# --- CONSOLIDATION AND DEDUPLICATION ---\n",
        "\n",
        "if all_processed_dfs:\n",
        "    df = pd.concat(all_processed_dfs, ignore_index=True)\n",
        "    print(f\"\\n--- All files concatenated. Initial total rows: {len(df)} ---\")\n",
        "\n",
        "    # Remove duplicate contracts based on 'CN ID' (Contract Notice ID)\n",
        "    # This prevents counting the same contract multiple times if it was found in different searches.\n",
        "    original_rows = len(df)\n",
        "    if 'CN ID' in df.columns:\n",
        "        df.drop_duplicates(subset=['CN ID'], keep='first', inplace=True)\n",
        "        deduplicated_rows = len(df)\n",
        "        print(f\"--- Deduplicated {original_rows - deduplicated_rows} rows. Remaining unique contracts: {deduplicated_rows} ---\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è 'CN ID' column not found for deduplication. Skipping deduplication.\")\n",
        "        deduplicated_rows = original_rows\n",
        "\n",
        "    print(\"\\n‚úÖ Final Consolidated Data loaded for analysis.\")\n",
        "    print(f\"Total unique contracts: {deduplicated_rows}\")\n",
        "    print(\"Columns in final DataFrame:\", list(df.columns))\n",
        "    print(\"First 5 rows of consolidated data:\")\n",
        "    print(df.head())\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå No data frames were successfully processed. PACE engine cannot proceed.\")\n",
        "    # Exit here if no data was loaded at all\n",
        "    raise SystemExit(\"No data loaded to process.\") # Nicer way to exit in Colab than exit()\n",
        "\n",
        "# --- PACE MODULE 2: CORE ANALYSIS ---\n",
        "\n",
        "# Ensure Clean_Value is numeric (important for sum operations later)\n",
        "df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "\n",
        "# Analysis A: Total Spend by the Consolidated Big 4 Entities\n",
        "# Define the Big 4 firms for consolidated reporting\n",
        "big_4_firms = [\n",
        "    'PwC (Consolidated)',\n",
        "    'Deloitte (Consolidated)',\n",
        "    'EY (Consolidated)',\n",
        "    'KPMG (Consolidated)'\n",
        "]\n",
        "\n",
        "# Analysis B: The \"Vague Description\" Hunter (now smarter!)\n",
        "vague_keywords = [\n",
        "    'management advisory services', 'consulting service', 'strategic advice',\n",
        "    'professional services', 'advisory services', 'business advisory services',\n",
        "    'support services', 'review services', 'quality assurance',\n",
        "    'advisory support', 'program management', 'capacity building',\n",
        "    'evaluation services', 'transformation services', 'change management'\n",
        "]\n",
        "\n",
        "vague_pattern = '|'.join(vague_keywords)\n",
        "keyword_vague_data = df[\n",
        "    df['Title'].fillna('').str.lower().str.contains(vague_pattern, na=False)\n",
        "]\n",
        "\n",
        "short_titles_data = df[\n",
        "    df['Title'].fillna('').apply(lambda x: len(str(x).split())) < 4\n",
        "]\n",
        "\n",
        "vague_data = pd.concat([keyword_vague_data, short_titles_data]).drop_duplicates(subset=['CN ID'])\n",
        "\n",
        "total_vague = vague_data['Clean_Value'].sum()\n",
        "vague_count = len(vague_data)\n",
        "\n",
        "\n",
        "# Analysis C: The \"Just Under Threshold\" Hunter\n",
        "threshold_min = 70000.00\n",
        "threshold_max = 79999.99\n",
        "\n",
        "just_under_threshold_data = df[\n",
        "    (df['Clean_Value'] >= threshold_min) &\n",
        "    (df['Clean_Value'] <= threshold_max)\n",
        "]\n",
        "total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "# Analysis D: The \"Super Red Flag\" Hunter (Vague AND Just Under Threshold)\n",
        "super_red_flag_data = pd.merge(\n",
        "    vague_data[['CN ID', 'Clean_Value']],\n",
        "    just_under_threshold_data[['CN ID', 'Clean_Value']],\n",
        "    on='CN ID',\n",
        "    how='inner'\n",
        ")\n",
        "super_red_flag_count = len(super_red_flag_data)\n",
        "super_red_flag_total = super_red_flag_data['Clean_Value_x'].sum()\n",
        "\n",
        "\n",
        "# --- PACE MODULE 3: REPORTING ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"      PACE ENGINE - CONSOLIDATED REPORT      \")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Report for each of the Big 4 firms\n",
        "total_big_4_spend = 0\n",
        "for firm in big_4_firms:\n",
        "    firm_data = df[df['Clean_Supplier'] == firm]\n",
        "    firm_spend = firm_data['Clean_Value'].sum()\n",
        "    total_big_4_spend += firm_spend\n",
        "    # Check if the firm was actually found in the data before printing\n",
        "    if firm_spend > 0:\n",
        "        print(f\"üí∞ Total Spend with {firm:<22}: ${firm_spend:,.2f}\")\n",
        "\n",
        "print(f\"\\nüìà Grand Total Big 4 Spend (in this data): ${total_big_4_spend:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "print(f\"üö® Super Red Flag (Vague & Under Threshold): {super_red_flag_count}\")\n",
        "print(f\"üí≤ Value of Super Red Flag Contracts: ${super_red_flag_total:,.2f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# --- Sample Outputs for each category ---\n",
        "\n",
        "print(\"\\n--- Sample of Vague Contracts Found: ---\")\n",
        "if not vague_data.empty:\n",
        "    original_vague_contracts = df[df['CN ID'].isin(vague_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name'] # Added Supplier Name\n",
        "    actual_display_cols = [col for col in display_cols if col in original_vague_contracts.columns]\n",
        "    print(original_vague_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Just Under Threshold' Contracts Found: ---\")\n",
        "if not just_under_threshold_data.empty:\n",
        "    original_threshold_contracts = df[df['CN ID'].isin(just_under_threshold_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name'] # Added Supplier Name\n",
        "    actual_display_cols = [col for col in display_cols if col in original_threshold_contracts.columns]\n",
        "    print(original_threshold_contracts[actual_display_cols].head(5))\n",
        "else:\n",
        "    print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "print(\"\\n--- Sample of 'Super Red Flag' Contracts Found: ---\")\n",
        "if not super_red_flag_data.empty:\n",
        "    original_super_red_flags = df[df['CN ID'].isin(super_red_flag_data['CN ID'])]\n",
        "    display_cols = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name'] # Added Supplier Name\n",
        "    actual_display_cols = [col for col in display_cols if col in original_super_red_flags.columns]\n",
        "    print(original_super_red_flags[actual_display_cols].head())\n",
        "else:\n",
        "    print(\"No 'Super Red Flag' contracts found in this sample.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mvC0Zyl6sk5",
        "outputId": "da731196-6360-4a49-ab0a-42dc05b7a435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Multi-File Ingestion ---\n",
            "\n",
            "Processing file: pwc_pace_data.csv...\n",
            "‚úÖ Success! Data loaded and headers assigned from pwc_pace_data.csv.\n",
            "  Rows loaded and cleaned: 155\n",
            "\n",
            "Processing file: deloitte_pace_data.csv...\n",
            "‚ùå Error processing 'deloitte_pace_data.csv': 'utf-8' codec can't decode byte 0x96 in position 31: invalid start byte\n",
            "\n",
            "Processing file: kpmg_pace_data.csv...\n",
            "‚ùå Error processing 'kpmg_pace_data.csv': 'utf-8' codec can't decode byte 0x92 in position 20: invalid start byte\n",
            "\n",
            "Processing file: ey_pace_data.csv...\n",
            "‚úÖ Success! Data loaded and headers assigned from ey_pace_data.csv.\n",
            "  Rows loaded and cleaned: 72\n",
            "\n",
            "--- All files concatenated. Initial total rows: 227 ---\n",
            "--- Deduplicated 0 rows. Remaining unique contracts: 227 ---\n",
            "\n",
            "‚úÖ Final Consolidated Data loaded for analysis.\n",
            "Total unique contracts: 227\n",
            "Columns in final DataFrame: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan), 'Clean_Supplier', 'Clean_Value']\n",
            "First 5 rows of consolidated data:\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \\\n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN   \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN   \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN   \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN   \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN   \n",
            "\n",
            "1      Clean_Supplier  Clean_Value  \n",
            "0  PwC (Consolidated)     26500.00  \n",
            "1  PwC (Consolidated)    163900.00  \n",
            "2  PwC (Consolidated)    770000.00  \n",
            "3  PwC (Consolidated)    179502.19  \n",
            "4  PwC (Consolidated)     26500.00  \n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - CONSOLIDATED REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated)    : $202,578,938.13\n",
            "üí∞ Total Spend with EY (Consolidated)     : $20,892,038.69\n",
            "\n",
            "üìà Grand Total Big 4 Spend (in this data): $223,470,976.82\n",
            "========================================\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   106\n",
            "üí∏ Total Value of Vague Contracts:      $70,348,354.92\n",
            "üìâ Contracts Just Under $80k Threshold: 15\n",
            "üíµ Value of Just Under Threshold Contracts: $1,165,226.05\n",
            "üö® Super Red Flag (Vague & Under Threshold): 7\n",
            "üí≤ Value of Super Red Flag Contracts: $542,712.00\n",
            "========================================\n",
            "\n",
            "--- Sample of Vague Contracts Found: ---\n",
            "1                                             Agency  \\\n",
            "0  Department of Infrastructure, Transport, Regio...   \n",
            "4  Department of Infrastructure, Transport, Regio...   \n",
            "6                     Australian Signals Directorate   \n",
            "7  Office of the Official Secretary to the Govern...   \n",
            "8                              Department of Defence   \n",
            "\n",
            "1                         Title Value (AUD)  \\\n",
            "0     Data Subscription Service   26,500.00   \n",
            "4        Media Outlook Services   26,500.00   \n",
            "6           Soundproofing Works   13,241.42   \n",
            "7  Management advisory services   75,000.00   \n",
            "8   Leadership Pathway Training   35,200.00   \n",
            "\n",
            "1                                      Supplier Name  \n",
            "0                         PWC PRODUCT SALES LLC (US)  \n",
            "4                         PwC Product Sales LLC (US)  \n",
            "6                                 PWC PROPERTY WORKS  \n",
            "7  PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "8                         PWC CONSULTING PTY LIMITED  \n",
            "\n",
            "--- Sample of 'Just Under Threshold' Contracts Found: ---\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \\\n",
            "7      Management advisory services   75,000.00   \n",
            "13  Data Workforce Plan Development   75,542.00   \n",
            "22               Accounting Support   79,092.00   \n",
            "49              WFP Special Project   75,000.00   \n",
            "77                Quality Framework   78,810.00   \n",
            "\n",
            "1                                       Supplier Name  \n",
            "7   PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "13                                                PWC  \n",
            "22                                                PwC  \n",
            "49                         PwC Consulting (Australia)  \n",
            "77                  PwC Strategy& (Australia) Pty Ltd  \n",
            "\n",
            "--- Sample of 'Super Red Flag' Contracts Found: ---\n",
            "1                                               Agency  \\\n",
            "7    Office of the Official Secretary to the Govern...   \n",
            "22   Office of the Official Secretary to the Govern...   \n",
            "49                       Attorney-General's Department   \n",
            "77                                  Services Australia   \n",
            "112                              Department of Defence   \n",
            "\n",
            "1                           Title Value (AUD)  \\\n",
            "7    Management advisory services   75,000.00   \n",
            "22             Accounting Support   79,092.00   \n",
            "49            WFP Special Project   75,000.00   \n",
            "77              Quality Framework   78,810.00   \n",
            "112           Contractor Services   75,612.50   \n",
            "\n",
            "1                                        Supplier Name  \n",
            "7    PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "22                                                 PwC  \n",
            "49                          PwC Consulting (Australia)  \n",
            "77                   PwC Strategy& (Australia) Pty Ltd  \n",
            "112                    PWC STRATEGY&(AUSTRALIA)PTY LTD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V11): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA with utf-8 encoding and the determined skiprows=16\n",
        "    # Use header=None initially to tell pandas not to guess the header.\n",
        "    df = pd.read_csv('pace_data.csv', encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "    # Debug step: Print what the DataFrame looks like immediately after loading\n",
        "    print(\"--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\")\n",
        "    print(df.head(3)) # Print first THREE rows to see potential headers and the empty row\n",
        "    print(\"--- END RAW DATA DEBUG ---\")\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS (using the row at index 1 for headers)\n",
        "    # The actual headers are in the second row (index 1) of our loaded DataFrame.\n",
        "    df.columns = df.iloc[1]\n",
        "\n",
        "    # Then, drop the first two rows (the NaN row at index 0 and the header row at index 1)\n",
        "    # from the DataFrame, as they are no longer part of the data.\n",
        "    df = df[2:].reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (after header assignment):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter (now smarter!)\n",
        "\n",
        "    # List of keywords that indicate a potentially vague description\n",
        "    vague_keywords = [\n",
        "        'management advisory services',\n",
        "        'consulting service',\n",
        "        'strategic advice',\n",
        "        'professional services',\n",
        "        'advisory services',\n",
        "        'business advisory services',\n",
        "        'support services',\n",
        "        'review services',\n",
        "        'quality assurance',\n",
        "        'advisory support', # Added another common one\n",
        "        'program management' # Another common vague one\n",
        "    ]\n",
        "\n",
        "    # 1. Look for specific vague keywords\n",
        "    # Create a regex pattern to search for any of the vague keywords (case-insensitive)\n",
        "    vague_pattern = '|'.join(vague_keywords)\n",
        "\n",
        "    # Filter for titles containing any of the vague keywords\n",
        "    keyword_vague_data = df[\n",
        "        df['Title'].fillna('').str.lower().str.contains(vague_pattern, na=False)\n",
        "    ]\n",
        "\n",
        "    # 2. Look for extremely short titles (e.g., less than 4 words)\n",
        "    short_titles_data = df[\n",
        "        df['Title'].fillna('').apply(lambda x: len(str(x).split())) < 4\n",
        "    ]\n",
        "\n",
        "    # Combine both criteria: contracts that match vague keywords OR have very short titles\n",
        "    # Use .drop_duplicates() to count each unique contract only once\n",
        "    vague_data = pd.concat([keyword_vague_data, short_titles_data]).drop_duplicates(subset=['CN ID'])\n",
        "\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "\n",
        "    # Analysis C: The \"Just Under Threshold\" Hunter\n",
        "    # Flagging contracts between $70,000 and $79,999 (inclusive)\n",
        "    threshold_min = 70000.00\n",
        "    threshold_max = 79999.99 # To be inclusive up to $79,999\n",
        "\n",
        "    just_under_threshold_data = df[\n",
        "        (df['Clean_Value'] >= threshold_min) &\n",
        "        (df['Clean_Value'] <= threshold_max)\n",
        "    ]\n",
        "    total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "    count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "    # Analysis D: The \"Super Red Flag\" Hunter (Vague AND Just Under Threshold)\n",
        "    # Find contracts that appear in BOTH vague_data AND just_under_threshold_data\n",
        "\n",
        "    # We use pandas .merge() to find the common CN IDs between the two sets\n",
        "    super_red_flag_data = pd.merge(\n",
        "        vague_data[['CN ID', 'Clean_Value']],\n",
        "        just_under_threshold_data[['CN ID', 'Clean_Value']],\n",
        "        on='CN ID',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # The Clean_Value from the merge might be duplicated or from vague_data, so we'll re-calculate from original df\n",
        "    super_red_flag_count = len(super_red_flag_data)\n",
        "    super_red_flag_total = super_red_flag_data['Clean_Value_x'].sum() # or Clean_Value_y, they should be the same\n",
        "\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "    print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "    print(f\"üö® Super Red Flag (Vague & Under Threshold): {super_red_flag_count}\")\n",
        "    print(f\"üí≤ Value of Super Red Flag Contracts: ${super_red_flag_total:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    if not vague_data.empty:\n",
        "        display_cols = ['Agency', 'Title', 'Value (AUD)']\n",
        "        actual_display_cols = [col for col in display_cols if col in vague_data.columns]\n",
        "        print(vague_data[actual_display_cols].head(5)) # Changed to print top 5\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "    # Optional: Show a sample of 'Just Under Threshold' contracts\n",
        "    if not just_under_threshold_data.empty:\n",
        "        print(\"\\nSample of 'Just Under Threshold' Contracts Found:\")\n",
        "        display_cols = ['Agency', 'Title', 'Value (AUD)']\n",
        "        actual_display_cols = [col for col in display_cols if col in just_under_threshold_data.columns]\n",
        "        print(just_under_threshold_data[actual_display_cols].head(5)) # Changed to print top 5\n",
        "    else:\n",
        "        print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "    # Optional: Show a sample of 'Super Red Flag' contracts\n",
        "    if not super_red_flag_data.empty:\n",
        "        print(\"\\nSample of 'Super Red Flag' Contracts Found:\")\n",
        "        # We need to get the original data for these CN IDs for full details\n",
        "        original_super_red_flags = df[df['CN ID'].isin(super_red_flag_data['CN ID'])]\n",
        "        display_cols_for_super = ['Agency', 'Title', 'Value (AUD)', 'Supplier Name'] # Added Supplier Name\n",
        "        actual_display_cols_for_super = [col for col in display_cols_for_super if col in original_super_red_flags.columns]\n",
        "        print(original_super_red_flags[actual_display_cols_for_super].head())\n",
        "    else:\n",
        "        print(\"No 'Super Red Flag' contracts found in this sample.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f5odt9g1_-u",
        "outputId": "53aec5fa-3bbe-40b5-f53d-8c69ec6290cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\n",
            "          0                          1   \\\n",
            "0        NaN                        NaN   \n",
            "1      CN ID                      Title   \n",
            "2  CN4033077  Data Subscription Service   \n",
            "\n",
            "                                                  2             3   \\\n",
            "0                                                NaN           NaN   \n",
            "1                                             Agency  Publish Date   \n",
            "2  Department of Infrastructure, Transport, Regio...      6-Feb-24   \n",
            "\n",
            "              4                    5               6                  7   \\\n",
            "0            NaN                  NaN             NaN                NaN   \n",
            "1       Category  Contract Start Date  Execution Date  Contract End Date   \n",
            "2  Data services            17-Jan-24             NaN          16-Jan-25   \n",
            "\n",
            "            8       9                           10                 11  12  \n",
            "0          NaN     NaN                         NaN                NaN NaN  \n",
            "1  Value (AUD)  ATM ID               Supplier Name       Last Updated NaN  \n",
            "2    26,500.00     NaN  PWC PRODUCT SALES LLC (US)  06-Feb-24 3:30 pm NaN  \n",
            "--- END RAW DATA DEBUG ---\n",
            "\n",
            "‚úÖ Success! Data loaded and headers correctly assigned.\n",
            "Total rows found: 155\n",
            "Columns found: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan)]\n",
            "\n",
            "First 5 rows of actual data (after header assignment):\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN  \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN  \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN  \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN  \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN  \n",
            "‚úÖ Supplier names standardized.\n",
            "‚úÖ Money values standardized.\n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - INITIAL REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated): $202,578,938.13\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   69\n",
            "üí∏ Total Value of Vague Contracts:      $59,919,784.81\n",
            "üìâ Contracts Just Under $80k Threshold: 8\n",
            "üíµ Value of Just Under Threshold Contracts: $618,306.80\n",
            "üö® Super Red Flag (Vague & Under Threshold): 5\n",
            "üí≤ Value of Super Red Flag Contracts: $383,514.50\n",
            "========================================\n",
            "\n",
            "Sample of Vague Contracts Found:\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "9     Australian Building and Construction Commission   \n",
            "27                            Department of Education   \n",
            "45  Department of Employment, Skills, Small and Fa...   \n",
            "48                      Attorney-General's Department   \n",
            "\n",
            "1                                               Title Value (AUD)  \n",
            "7                        Management advisory services   75,000.00  \n",
            "9   Payroll voluntary redundancy advisory services...  151,470.00  \n",
            "27                               Support Services CSS  227,389.10  \n",
            "45       Quality Assurance Framework Auditor Training   32,783.00  \n",
            "48   Review services - Workforce reporting dashboards   53,000.00  \n",
            "\n",
            "Sample of 'Just Under Threshold' Contracts Found:\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \n",
            "7      Management advisory services   75,000.00  \n",
            "13  Data Workforce Plan Development   75,542.00  \n",
            "22               Accounting Support   79,092.00  \n",
            "49              WFP Special Project   75,000.00  \n",
            "77                Quality Framework   78,810.00  \n",
            "\n",
            "Sample of 'Super Red Flag' Contracts Found:\n",
            "1                                               Agency  \\\n",
            "7    Office of the Official Secretary to the Govern...   \n",
            "22   Office of the Official Secretary to the Govern...   \n",
            "49                       Attorney-General's Department   \n",
            "77                                  Services Australia   \n",
            "112                              Department of Defence   \n",
            "\n",
            "1                           Title Value (AUD)  \\\n",
            "7    Management advisory services   75,000.00   \n",
            "22             Accounting Support   79,092.00   \n",
            "49            WFP Special Project   75,000.00   \n",
            "77              Quality Framework   78,810.00   \n",
            "112           Contractor Services   75,612.50   \n",
            "\n",
            "1                                        Supplier Name  \n",
            "7    PwC PricewaterhouseCoopers Consulting (Austral...  \n",
            "22                                                 PwC  \n",
            "49                          PwC Consulting (Australia)  \n",
            "77                   PwC Strategy& (Australia) Pty Ltd  \n",
            "112                    PWC STRATEGY&(AUSTRALIA)PTY LTD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V10): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA with utf-8 encoding and the determined skiprows=16\n",
        "    # Use header=None initially to tell pandas not to guess the header.\n",
        "    df = pd.read_csv('pace_data.csv', encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "    # Debug step: Print what the DataFrame looks like immediately after loading\n",
        "    print(\"--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\")\n",
        "    print(df.head(3)) # Print first THREE rows to see potential headers and the empty row\n",
        "    print(\"--- END RAW DATA DEBUG ---\")\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS (using the row at index 1 for headers)\n",
        "    # The actual headers are in the second row (index 1) of our loaded DataFrame.\n",
        "    df.columns = df.iloc[1]\n",
        "\n",
        "    # Then, drop the first two rows (the NaN row at index 0 and the header row at index 1)\n",
        "    # from the DataFrame, as they are no longer part of the data.\n",
        "    df = df[2:].reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (after header assignment):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter (now smarter!)\n",
        "\n",
        "    # List of keywords that indicate a potentially vague description\n",
        "    vague_keywords = [\n",
        "        'management advisory services',\n",
        "        'consulting service',\n",
        "        'strategic advice',\n",
        "        'professional services',\n",
        "        'advisory services',\n",
        "        'business advisory services',\n",
        "        'support services',\n",
        "        'review services', # Added based on your screenshot's \"Review of the Department's Reconciliation Action Plan\"\n",
        "        'quality assurance' # Another one from your screenshot \"Quality Assurance Framework\"\n",
        "    ]\n",
        "\n",
        "    # 1. Look for specific vague keywords\n",
        "    # Create a regex pattern to search for any of the vague keywords (case-insensitive)\n",
        "    vague_pattern = '|'.join(vague_keywords)\n",
        "\n",
        "    # Filter for titles containing any of the vague keywords\n",
        "    keyword_vague_data = df[\n",
        "        df['Title'].fillna('').str.lower().str.contains(vague_pattern, na=False)\n",
        "    ]\n",
        "\n",
        "    # 2. Look for extremely short titles (e.g., less than 4 words)\n",
        "    short_titles_data = df[\n",
        "        df['Title'].fillna('').apply(lambda x: len(str(x).split())) < 4\n",
        "    ]\n",
        "\n",
        "    # Combine both criteria: contracts that match vague keywords OR have very short titles\n",
        "    # Use .drop_duplicates() to count each unique contract only once\n",
        "    vague_data = pd.concat([keyword_vague_data, short_titles_data]).drop_duplicates(subset=['CN ID'])\n",
        "\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "\n",
        "    # Analysis C: The \"Just Under Threshold\" Hunter\n",
        "    # Flagging contracts between $70,000 and $79,999 (inclusive)\n",
        "    threshold_min = 70000.00\n",
        "    threshold_max = 79999.99 # To be inclusive up to $79,999\n",
        "\n",
        "    just_under_threshold_data = df[\n",
        "        (df['Clean_Value'] >= threshold_min) &\n",
        "        (df['Clean_Value'] <= threshold_max)\n",
        "    ]\n",
        "    total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "    count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "    print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    if not vague_data.empty:\n",
        "        display_cols = ['Agency', 'Title', 'Value (AUD)']\n",
        "        actual_display_cols = [col for col in display_cols if col in vague_data.columns]\n",
        "        print(vague_data[actual_display_cols].head(5)) # Changed to print top 5\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "    # Optional: Show a sample of 'Just Under Threshold' contracts\n",
        "    if not just_under_threshold_data.empty:\n",
        "        print(\"\\nSample of 'Just Under Threshold' Contracts Found:\")\n",
        "        display_cols = ['Agency', 'Title', 'Value (AUD)']\n",
        "        actual_display_cols = [col for col in display_cols if col in just_under_threshold_data.columns]\n",
        "        print(just_under_threshold_data[actual_display_cols].head(5)) # Changed to print top 5\n",
        "    else:\n",
        "        print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMBIWGlZ1nlY",
        "outputId": "a10d33c2-bec3-492d-dcbc-1c2282a8eb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\n",
            "          0                          1   \\\n",
            "0        NaN                        NaN   \n",
            "1      CN ID                      Title   \n",
            "2  CN4033077  Data Subscription Service   \n",
            "\n",
            "                                                  2             3   \\\n",
            "0                                                NaN           NaN   \n",
            "1                                             Agency  Publish Date   \n",
            "2  Department of Infrastructure, Transport, Regio...      6-Feb-24   \n",
            "\n",
            "              4                    5               6                  7   \\\n",
            "0            NaN                  NaN             NaN                NaN   \n",
            "1       Category  Contract Start Date  Execution Date  Contract End Date   \n",
            "2  Data services            17-Jan-24             NaN          16-Jan-25   \n",
            "\n",
            "            8       9                           10                 11  12  \n",
            "0          NaN     NaN                         NaN                NaN NaN  \n",
            "1  Value (AUD)  ATM ID               Supplier Name       Last Updated NaN  \n",
            "2    26,500.00     NaN  PWC PRODUCT SALES LLC (US)  06-Feb-24 3:30 pm NaN  \n",
            "--- END RAW DATA DEBUG ---\n",
            "\n",
            "‚úÖ Success! Data loaded and headers correctly assigned.\n",
            "Total rows found: 155\n",
            "Columns found: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan)]\n",
            "\n",
            "First 5 rows of actual data (after header assignment):\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN  \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN  \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN  \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN  \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN  \n",
            "‚úÖ Supplier names standardized.\n",
            "‚úÖ Money values standardized.\n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - INITIAL REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated): $202,578,938.13\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   69\n",
            "üí∏ Total Value of Vague Contracts:      $59,919,784.81\n",
            "üìâ Contracts Just Under $80k Threshold: 8\n",
            "üíµ Value of Just Under Threshold Contracts: $618,306.80\n",
            "========================================\n",
            "\n",
            "Sample of Vague Contracts Found:\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "9     Australian Building and Construction Commission   \n",
            "27                            Department of Education   \n",
            "45  Department of Employment, Skills, Small and Fa...   \n",
            "48                      Attorney-General's Department   \n",
            "\n",
            "1                                               Title Value (AUD)  \n",
            "7                        Management advisory services   75,000.00  \n",
            "9   Payroll voluntary redundancy advisory services...  151,470.00  \n",
            "27                               Support Services CSS  227,389.10  \n",
            "45       Quality Assurance Framework Auditor Training   32,783.00  \n",
            "48   Review services - Workforce reporting dashboards   53,000.00  \n",
            "\n",
            "Sample of 'Just Under Threshold' Contracts Found:\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \n",
            "7      Management advisory services   75,000.00  \n",
            "13  Data Workforce Plan Development   75,542.00  \n",
            "22               Accounting Support   79,092.00  \n",
            "49              WFP Special Project   75,000.00  \n",
            "77                Quality Framework   78,810.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V9): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA with utf-8 encoding and the determined skiprows=16\n",
        "    # Use header=None initially to tell pandas not to guess the header.\n",
        "    df = pd.read_csv('pace_data.csv', encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "    # Debug step: Print what the DataFrame looks like immediately after loading\n",
        "    print(\"--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\")\n",
        "    print(df.head(3)) # Print first THREE rows to see potential headers and the empty row\n",
        "    print(\"--- END RAW DATA DEBUG ---\")\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS (using the row at index 1 for headers)\n",
        "    # The actual headers are in the second row (index 1) of our loaded DataFrame.\n",
        "    df.columns = df.iloc[1]\n",
        "\n",
        "    # Then, drop the first two rows (the NaN row at index 0 and the header row at index 1)\n",
        "    # from the DataFrame, as they are no longer part of the data.\n",
        "    df = df[2:].reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (after header assignment):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower().str.strip() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # Analysis C: The \"Just Under Threshold\" Hunter\n",
        "    # Flagging contracts between $70,000 and $79,999 (inclusive)\n",
        "    threshold_min = 70000.00\n",
        "    threshold_max = 79999.99 # To be inclusive up to $79,999\n",
        "\n",
        "    just_under_threshold_data = df[\n",
        "        (df['Clean_Value'] >= threshold_min) &\n",
        "        (df['Clean_Value'] <= threshold_max)\n",
        "    ]\n",
        "    total_just_under_threshold = just_under_threshold_data['Clean_Value'].sum()\n",
        "    count_just_under_threshold = len(just_under_threshold_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(f\"üìâ Contracts Just Under $80k Threshold: {count_just_under_threshold}\")\n",
        "    print(f\"üíµ Value of Just Under Threshold Contracts: ${total_just_under_threshold:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    if not vague_data.empty:\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "    # Optional: Show a sample of 'Just Under Threshold' contracts\n",
        "    if not just_under_threshold_data.empty:\n",
        "        print(\"\\nSample of 'Just Under Threshold' Contracts Found:\")\n",
        "        display_cols = ['Agency', 'Title', 'Value (AUD)']\n",
        "        actual_display_cols = [col for col in display_cols if col in just_under_threshold_data.columns]\n",
        "        print(just_under_threshold_data[actual_display_cols].head())\n",
        "    else:\n",
        "        print(\"No 'Just Under Threshold' contracts found in this sample.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PZK-TmNyN_X",
        "outputId": "41cba7b6-890d-4e76-b8f2-0ebe0b47aea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\n",
            "          0                          1   \\\n",
            "0        NaN                        NaN   \n",
            "1      CN ID                      Title   \n",
            "2  CN4033077  Data Subscription Service   \n",
            "\n",
            "                                                  2             3   \\\n",
            "0                                                NaN           NaN   \n",
            "1                                             Agency  Publish Date   \n",
            "2  Department of Infrastructure, Transport, Regio...      6-Feb-24   \n",
            "\n",
            "              4                    5               6                  7   \\\n",
            "0            NaN                  NaN             NaN                NaN   \n",
            "1       Category  Contract Start Date  Execution Date  Contract End Date   \n",
            "2  Data services            17-Jan-24             NaN          16-Jan-25   \n",
            "\n",
            "            8       9                           10                 11  12  \n",
            "0          NaN     NaN                         NaN                NaN NaN  \n",
            "1  Value (AUD)  ATM ID               Supplier Name       Last Updated NaN  \n",
            "2    26,500.00     NaN  PWC PRODUCT SALES LLC (US)  06-Feb-24 3:30 pm NaN  \n",
            "--- END RAW DATA DEBUG ---\n",
            "\n",
            "‚úÖ Success! Data loaded and headers correctly assigned.\n",
            "Total rows found: 155\n",
            "Columns found: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan)]\n",
            "\n",
            "First 5 rows of actual data (after header assignment):\n",
            "1         CN ID                                              Title  \\\n",
            "0     CN4033077                          Data Subscription Service   \n",
            "1     CN3968686  Addressing skills needs through online micro-c...   \n",
            "2     CN3959588  For Delivery of Independent Assurance: Onboard...   \n",
            "3  CN3913172-A2            Transfer from Purchase order 4500146910   \n",
            "4     CN3942498                             Media Outlook Services   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0  Department of Infrastructure, Transport, Regio...     6-Feb-24   \n",
            "1                            Department of Education    26-May-23   \n",
            "2   Department of Employment and Workplace Relations    20-Apr-23   \n",
            "3                Australian Skills Quality Authority    14-Sep-22   \n",
            "4  Department of Infrastructure, Transport, Regio...    25-Jan-23   \n",
            "\n",
            "1                         Category Contract Start Date Execution Date  \\\n",
            "0                    Data services           17-Jan-24            NaN   \n",
            "1  Education and Training Services           20-Apr-23            NaN   \n",
            "2                Computer services           21-Feb-23            NaN   \n",
            "3                Computer services            2-Sep-22            NaN   \n",
            "4                    Data services           16-Jan-23            NaN   \n",
            "\n",
            "1 Contract End Date Value (AUD)      ATM ID  \\\n",
            "0         16-Jan-25   26,500.00         NaN   \n",
            "1         22-Mar-24  163,900.00  ESE22/4797   \n",
            "2         20-Feb-24  770,000.00         NaN   \n",
            "3         31-Oct-22  179,502.19  DTA-487 V4   \n",
            "4         16-Jan-24   26,500.00         NaN   \n",
            "\n",
            "1                          Supplier Name        Last Updated  NaN  \n",
            "0             PWC PRODUCT SALES LLC (US)   06-Feb-24 3:30 pm  NaN  \n",
            "1                                    PWC  26-May-23 12:04 pm  NaN  \n",
            "2  PWC PRICEWATERHOUSECOOPERS CONSULTING   20-Apr-23 5:49 pm  NaN  \n",
            "3      PWC Consulting (AUST) Pty Limited  03-Feb-23 12:35 pm  NaN  \n",
            "4             PwC Product Sales LLC (US)   25-Jan-23 4:13 pm  NaN  \n",
            "‚úÖ Supplier names standardized.\n",
            "‚úÖ Money values standardized.\n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - INITIAL REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated): $202,578,938.13\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   3\n",
            "üí∏ Total Value of Vague Contracts:      $272,897.00\n",
            "üìâ Contracts Just Under $80k Threshold: 8\n",
            "üíµ Value of Just Under Threshold Contracts: $618,306.80\n",
            "========================================\n",
            "\n",
            "Sample of Vague Contracts Found:\n",
            "1                                               Agency  \\\n",
            "7    Office of the Official Secretary to the Govern...   \n",
            "60                          Department of the Treasury   \n",
            "127                         Department of the Treasury   \n",
            "\n",
            "1                           Title Value (AUD)  \n",
            "7    Management advisory services   75,000.00  \n",
            "60   Management advisory services   68,750.00  \n",
            "127  Management advisory services  129,147.00  \n",
            "\n",
            "Sample of 'Just Under Threshold' Contracts Found:\n",
            "1                                              Agency  \\\n",
            "7   Office of the Official Secretary to the Govern...   \n",
            "13                            Department of Education   \n",
            "22  Office of the Official Secretary to the Govern...   \n",
            "49                      Attorney-General's Department   \n",
            "77                                 Services Australia   \n",
            "\n",
            "1                             Title Value (AUD)  \n",
            "7      Management advisory services   75,000.00  \n",
            "13  Data Workforce Plan Development   75,542.00  \n",
            "22               Accounting Support   79,092.00  \n",
            "49              WFP Special Project   75,000.00  \n",
            "77                Quality Framework   78,810.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V8): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA with utf-8 encoding and the determined skiprows=16\n",
        "    # Use header=None initially to tell pandas not to guess the header.\n",
        "    df = pd.read_csv('pace_data.csv', encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "    # Debug step: Print what the DataFrame looks like immediately after loading\n",
        "    print(\"--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\")\n",
        "    print(df.head(3)) # Print first THREE rows to see potential headers and the empty row\n",
        "    print(\"--- END RAW DATA DEBUG ---\")\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS (using the row at index 1 for headers)\n",
        "    # The actual headers are in the second row (index 1) of our loaded DataFrame.\n",
        "    df.columns = df.iloc[1]\n",
        "\n",
        "    # Then, drop the first two rows (the NaN row at index 0 and the header row at index 1)\n",
        "    # from the DataFrame, as they are no longer part of the data.\n",
        "    df = df[2:].reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (after header assignment):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower().str.strip() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        # Check if 'Agency' column exists before trying to display it\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMWiVXZLupxs",
        "outputId": "e124231b-58b8-4f90-efb7-448e9d8fd101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\n",
            "             0                                                  1   \\\n",
            "0           NaN                                                NaN   \n",
            "1         CN ID                                              Title   \n",
            "2  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "\n",
            "                        2             3                             4   \\\n",
            "0                      NaN           NaN                           NaN   \n",
            "1                   Agency  Publish Date                      Category   \n",
            "2  Department of Education     15-Oct-21  Management advisory services   \n",
            "\n",
            "                    5               6                  7             8   \\\n",
            "0                  NaN             NaN                NaN           NaN   \n",
            "1  Contract Start Date  Execution Date  Contract End Date   Value (AUD)   \n",
            "2             1-Oct-21             NaN           2-Oct-23  2,704,622.80   \n",
            "\n",
            "           9              10                 11  12  \n",
            "0         NaN            NaN                NaN NaN  \n",
            "1      ATM ID  Supplier Name       Last Updated NaN  \n",
            "2  RFT 5-2018            PWC  06-Jan-23 4:01 pm NaN  \n",
            "--- END RAW DATA DEBUG ---\n",
            "\n",
            "‚úÖ Success! Data loaded and headers correctly assigned.\n",
            "Total rows found: 48\n",
            "Columns found: ['CN ID', 'Title', 'Agency', 'Publish Date', 'Category', 'Contract Start Date', 'Execution Date', 'Contract End Date', 'Value (AUD)', 'ATM ID', 'Supplier Name', 'Last Updated', np.float64(nan)]\n",
            "\n",
            "First 5 rows of actual data (after header assignment):\n",
            "1         CN ID                                              Title  \\\n",
            "0  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "1     CN3922991                       Management advisory services   \n",
            "2     CN3903240  Payroll voluntary redundancy advisory services...   \n",
            "3     CN3900356              Supplier Accreditation System Support   \n",
            "4     CN3891576          Establishment of Indigenous Working Group   \n",
            "\n",
            "1                                             Agency Publish Date  \\\n",
            "0                            Department of Education    15-Oct-21   \n",
            "1  Office of the Official Secretary to the Govern...     8-Nov-22   \n",
            "2    Australian Building and Construction Commission     8-Aug-22   \n",
            "3                              Department of Defence    28-Jul-22   \n",
            "4                              Department of Defence     5-Jul-22   \n",
            "\n",
            "1                      Category Contract Start Date Execution Date  \\\n",
            "0  Management advisory services            1-Oct-21            NaN   \n",
            "1  Management advisory services           24-Oct-22            NaN   \n",
            "2  Management advisory services           29-Jul-22            NaN   \n",
            "3  Management advisory services            1-Aug-22            NaN   \n",
            "4  Management advisory services           14-Jun-22            NaN   \n",
            "\n",
            "1 Contract End Date   Value (AUD)      ATM ID  \\\n",
            "0          2-Oct-23  2,704,622.80  RFT 5-2018   \n",
            "1         30-Jun-23     75,000.00   CON000742   \n",
            "2         31-Oct-22    151,470.00         NaN   \n",
            "3         31-Dec-22     60,000.00         NaN   \n",
            "4         30-Nov-22    200,000.00         NaN   \n",
            "\n",
            "1                                      Supplier Name        Last Updated  NaN  \n",
            "0                                                PWC   06-Jan-23 4:01 pm  NaN  \n",
            "1  PwC PricewaterhouseCoopers Consulting (Austral...  08-Nov-22 11:33 am  NaN  \n",
            "2                       PWC - PRICEWATERHOUSECOOPERS   08-Aug-22 4:04 pm  NaN  \n",
            "3                         PWC CONSULTING PTY LIMITED   28-Jul-22 1:55 pm  NaN  \n",
            "4                         PWC CONSULTING PTY LIMITED   05-Jul-22 2:57 pm  NaN  \n",
            "‚úÖ Supplier names standardized.\n",
            "‚úÖ Money values standardized.\n",
            "\n",
            "========================================\n",
            "      PACE ENGINE - INITIAL REPORT      \n",
            "========================================\n",
            "üí∞ Total Spend with PwC (Consolidated): $58,264,393.95\n",
            "üå´Ô∏è  Contracts with Vague Descriptions:   3\n",
            "üí∏ Total Value of Vague Contracts:      $272,897.00\n",
            "========================================\n",
            "\n",
            "Sample of Vague Contracts Found:\n",
            "1                                              Agency  \\\n",
            "1   Office of the Official Secretary to the Govern...   \n",
            "23                         Department of the Treasury   \n",
            "42                         Department of the Treasury   \n",
            "\n",
            "1                          Title Value (AUD)  \n",
            "1   Management advisory services   75,000.00  \n",
            "23  Management advisory services   68,750.00  \n",
            "42  Management advisory services  129,147.00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V7): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA with utf-8 encoding and the determined skiprows=16\n",
        "    # We still use header=None initially to avoid pandas making assumptions.\n",
        "    df = pd.read_csv('pace_data.csv', encoding='utf-8', skiprows=16, header=None)\n",
        "\n",
        "    # Debug step: Print what the DataFrame looks like immediately after loading\n",
        "    print(\"--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\")\n",
        "    print(df.head(2)) # Print first two rows to see potential headers\n",
        "    print(\"--- END RAW DATA DEBUG ---\")\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS (assuming they are in the first row after skipping)\n",
        "    # The actual headers are in the first row (index 0) of our loaded DataFrame.\n",
        "    # We set these as the new column names.\n",
        "    df.columns = df.iloc[0]\n",
        "\n",
        "    # Then, we drop that row from the DataFrame, as it's now our header.\n",
        "    df = df[1:].reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (after header assignment):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower().str.strip() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        # Check if 'Agency' column exists before trying to display it\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-1Y_JPBuaUJ",
        "outputId": "cea6f97d-252e-4d4c-d62d-c4baf41a6385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAW DATA AFTER SKIPPING 16 ROWS (DEBUG) ---\n",
            "      0      1       2             3         4                    5   \\\n",
            "0    NaN    NaN     NaN           NaN       NaN                  NaN   \n",
            "1  CN ID  Title  Agency  Publish Date  Category  Contract Start Date   \n",
            "\n",
            "               6                  7            8       9              10  \\\n",
            "0             NaN                NaN          NaN     NaN            NaN   \n",
            "1  Execution Date  Contract End Date  Value (AUD)  ATM ID  Supplier Name   \n",
            "\n",
            "             11  12  \n",
            "0           NaN NaN  \n",
            "1  Last Updated NaN  \n",
            "--- END RAW DATA DEBUG ---\n",
            "\n",
            "‚úÖ Success! Data loaded and headers correctly assigned.\n",
            "Total rows found: 49\n",
            "Columns found: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, np.float64(nan)]\n",
            "\n",
            "First 5 rows of actual data (after header assignment):\n",
            "0           NaN                                                NaN  \\\n",
            "0         CN ID                                              Title   \n",
            "1  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "2     CN3922991                       Management advisory services   \n",
            "3     CN3903240  Payroll voluntary redundancy advisory services...   \n",
            "4     CN3900356              Supplier Accreditation System Support   \n",
            "\n",
            "0                                                NaN           NaN  \\\n",
            "0                                             Agency  Publish Date   \n",
            "1                            Department of Education     15-Oct-21   \n",
            "2  Office of the Official Secretary to the Govern...      8-Nov-22   \n",
            "3    Australian Building and Construction Commission      8-Aug-22   \n",
            "4                              Department of Defence     28-Jul-22   \n",
            "\n",
            "0                           NaN                  NaN             NaN  \\\n",
            "0                      Category  Contract Start Date  Execution Date   \n",
            "1  Management advisory services             1-Oct-21             NaN   \n",
            "2  Management advisory services            24-Oct-22             NaN   \n",
            "3  Management advisory services            29-Jul-22             NaN   \n",
            "4  Management advisory services             1-Aug-22             NaN   \n",
            "\n",
            "0                NaN           NaN         NaN  \\\n",
            "0  Contract End Date   Value (AUD)      ATM ID   \n",
            "1           2-Oct-23  2,704,622.80  RFT 5-2018   \n",
            "2          30-Jun-23     75,000.00   CON000742   \n",
            "3          31-Oct-22    151,470.00         NaN   \n",
            "4          31-Dec-22     60,000.00         NaN   \n",
            "\n",
            "0                                                NaN                 NaN  NaN  \n",
            "0                                      Supplier Name        Last Updated  NaN  \n",
            "1                                                PWC   06-Jan-23 4:01 pm  NaN  \n",
            "2  PwC PricewaterhouseCoopers Consulting (Austral...  08-Nov-22 11:33 am  NaN  \n",
            "3                       PWC - PRICEWATERHOUSECOOPERS   08-Aug-22 4:04 pm  NaN  \n",
            "4                         PWC CONSULTING PTY LIMITED   28-Jul-22 1:55 pm  NaN  \n",
            "\n",
            "‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V6): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "try:\n",
        "    # 1. LOAD THE DATA WITHOUT ASSUMING A HEADER INITIALLY\n",
        "    # We skip 16 rows, but tell pandas there's no header yet (header=None).\n",
        "    # This makes the \"CN ID, Title, Agency...\" row the first row of data (index 0).\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8559-1', skiprows=16, header=None)\n",
        "\n",
        "    # 2. MANUALLY SET THE HEADERS\n",
        "    # The actual headers are in the first row (index 0) of our loaded DataFrame.\n",
        "    # We set these as the new column names.\n",
        "    df.columns = df.iloc[0]\n",
        "\n",
        "    # Then, we drop that row from the DataFrame, as it's now our header.\n",
        "    df = df[1:].reset_index(drop=True)\n",
        "\n",
        "    print(\"‚úÖ Success! Data loaded and headers correctly assigned.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (including headers):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder for missing names\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    # Ensure 'Value (AUD)' column exists before trying to clean it\n",
        "    if 'Value (AUD)' in df.columns:\n",
        "        df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "        print(\"‚úÖ Money values standardized.\")\n",
        "    else:\n",
        "        print(\"‚ùå 'Value (AUD)' column not found after header assignment. Cannot standardize money.\")\n",
        "        df['Clean_Value'] = 0.0 # Assign a default to avoid further errors\n",
        "\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    # Ensure Clean_Value is numeric before summing\n",
        "    df['Clean_Value'] = pd.to_numeric(df['Clean_Value'], errors='coerce').fillna(0)\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower().str.strip() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        # Check if 'Agency' column exists before trying to display it\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nymU6yQGuGOZ",
        "outputId": "2569328a-f03c-424c-b876-af24fc707b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Error loading data: unknown encoding: ISO-8559-1\n",
            "\n",
            "‚ö†Ô∏è Still didn't find the expected column names. This indicates a persistent issue with CSV structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V5): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "# 1. LOAD THE DATA with the FINAL precise SKIPPING\n",
        "# Based on the latest output, the actual headers are on physical row 17 of the CSV,\n",
        "# so we need to skip the 16 rows before it (0-indexed).\n",
        "try:\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1', skiprows=16)\n",
        "\n",
        "    # We'll print the columns again to be absolutely sure\n",
        "    print(\"‚úÖ Success! Data loaded correctly.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (including headers):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "    print(\"‚úÖ Money values standardized.\")\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        # Check if 'Agency' column exists before trying to display it\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file again.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqrNmQ5Mtzv1",
        "outputId": "d9739705-9b0e-4690-fe11-b6b4d0bdfa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Data loaded correctly.\n",
            "Total rows found: 49\n",
            "Columns found: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n",
            "\n",
            "First 5 rows of actual data (including headers):\n",
            "     Unnamed: 0                                         Unnamed: 1  \\\n",
            "0         CN ID                                              Title   \n",
            "1  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "2     CN3922991                       Management advisory services   \n",
            "3     CN3903240  Payroll voluntary redundancy advisory services...   \n",
            "4     CN3900356              Supplier Accreditation System Support   \n",
            "\n",
            "                                          Unnamed: 2    Unnamed: 3  \\\n",
            "0                                             Agency  Publish Date   \n",
            "1                            Department of Education     15-Oct-21   \n",
            "2  Office of the Official Secretary to the Govern...      8-Nov-22   \n",
            "3    Australian Building and Construction Commission      8-Aug-22   \n",
            "4                              Department of Defence     28-Jul-22   \n",
            "\n",
            "                     Unnamed: 4           Unnamed: 5      Unnamed: 6  \\\n",
            "0                      Category  Contract Start Date  Execution Date   \n",
            "1  Management advisory services             1-Oct-21             NaN   \n",
            "2  Management advisory services            24-Oct-22             NaN   \n",
            "3  Management advisory services            29-Jul-22             NaN   \n",
            "4  Management advisory services             1-Aug-22             NaN   \n",
            "\n",
            "          Unnamed: 7    Unnamed: 8  Unnamed: 9  \\\n",
            "0  Contract End Date   Value (AUD)      ATM ID   \n",
            "1           2-Oct-23  2,704,622.80  RFT 5-2018   \n",
            "2          30-Jun-23     75,000.00   CON000742   \n",
            "3          31-Oct-22    151,470.00         NaN   \n",
            "4          31-Dec-22     60,000.00         NaN   \n",
            "\n",
            "                                         Unnamed: 10         Unnamed: 11  \\\n",
            "0                                      Supplier Name        Last Updated   \n",
            "1                                                PWC   06-Jan-23 4:01 pm   \n",
            "2  PwC PricewaterhouseCoopers Consulting (Austral...  08-Nov-22 11:33 am   \n",
            "3                       PWC - PRICEWATERHOUSECOOPERS   08-Aug-22 4:04 pm   \n",
            "4                         PWC CONSULTING PTY LIMITED   28-Jul-22 1:55 pm   \n",
            "\n",
            "   Unnamed: 12  \n",
            "0          NaN  \n",
            "1          NaN  \n",
            "2          NaN  \n",
            "3          NaN  \n",
            "4          NaN  \n",
            "\n",
            "‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V4): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np # Import numpy for NaN handling\n",
        "\n",
        "# 1. LOAD THE DATA with a more precise SKIPPING\n",
        "# Based on the latest output, the actual headers are on what would be row 16 of the CSV\n",
        "# (meaning we need to skip 15 rows before it).\n",
        "try:\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1', skiprows=15)\n",
        "\n",
        "    # We'll print the columns again to be absolutely sure\n",
        "    print(\"‚úÖ Success! Data loaded correctly.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (including headers):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        # Handle NaN values explicitly before converting to upper\n",
        "        if pd.isna(name):\n",
        "            return \"UNKNOWN\" # Or some other placeholder\n",
        "\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "    print(\"‚úÖ Money values standardized.\")\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        # Check if 'Agency' column exists before trying to display it\n",
        "        display_cols = ['Title', 'Value (AUD)']\n",
        "        if 'Agency' in vague_data.columns:\n",
        "            display_cols.insert(0, 'Agency')\n",
        "        print(vague_data[display_cols].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file again.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf7NkUuztPB8",
        "outputId": "a13639db-fa00-4414-afa7-09482f8d0be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Data loaded correctly.\n",
            "Total rows found: 50\n",
            "Columns found: ['Consultancy?', 'All', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n",
            "\n",
            "First 5 rows of actual data (including headers):\n",
            "   Consultancy?                                                All  \\\n",
            "0           NaN                                                NaN   \n",
            "1         CN ID                                              Title   \n",
            "2  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "3     CN3922991                       Management advisory services   \n",
            "4     CN3903240  Payroll voluntary redundancy advisory services...   \n",
            "\n",
            "                                          Unnamed: 2    Unnamed: 3  \\\n",
            "0                                                NaN           NaN   \n",
            "1                                             Agency  Publish Date   \n",
            "2                            Department of Education     15-Oct-21   \n",
            "3  Office of the Official Secretary to the Govern...      8-Nov-22   \n",
            "4    Australian Building and Construction Commission      8-Aug-22   \n",
            "\n",
            "                     Unnamed: 4           Unnamed: 5      Unnamed: 6  \\\n",
            "0                           NaN                  NaN             NaN   \n",
            "1                      Category  Contract Start Date  Execution Date   \n",
            "2  Management advisory services             1-Oct-21             NaN   \n",
            "3  Management advisory services            24-Oct-22             NaN   \n",
            "4  Management advisory services            29-Jul-22             NaN   \n",
            "\n",
            "          Unnamed: 7    Unnamed: 8  Unnamed: 9  \\\n",
            "0                NaN           NaN         NaN   \n",
            "1  Contract End Date   Value (AUD)      ATM ID   \n",
            "2           2-Oct-23  2,704,622.80  RFT 5-2018   \n",
            "3          30-Jun-23     75,000.00   CON000742   \n",
            "4          31-Oct-22    151,470.00         NaN   \n",
            "\n",
            "                                         Unnamed: 10         Unnamed: 11  \\\n",
            "0                                                NaN                 NaN   \n",
            "1                                      Supplier Name        Last Updated   \n",
            "2                                                PWC   06-Jan-23 4:01 pm   \n",
            "3  PwC PricewaterhouseCoopers Consulting (Austral...  08-Nov-22 11:33 am   \n",
            "4                       PWC - PRICEWATERHOUSECOOPERS   08-Aug-22 4:04 pm   \n",
            "\n",
            "   Unnamed: 12  \n",
            "0          NaN  \n",
            "1          NaN  \n",
            "2          NaN  \n",
            "3          NaN  \n",
            "4          NaN  \n",
            "\n",
            "‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V3): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. LOAD THE DATA with a more precise SKIPPING\n",
        "# Based on the screenshot, the actual headers are on row 17 (so skip 16 rows)\n",
        "try:\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1', skiprows=16)\n",
        "\n",
        "    # We'll print the columns again to be absolutely sure\n",
        "    print(\"‚úÖ Success! Data loaded correctly.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns))\n",
        "\n",
        "    # Let's also print the first 5 rows of the actual data to visually confirm\n",
        "    print(\"\\nFirst 5 rows of actual data (including headers):\")\n",
        "    print(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "# We're checking for a few key columns this time, just to be sure.\n",
        "if 'Supplier Name' in df.columns and 'Value (AUD)' in df.columns and 'Title' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Handle cases where value might be NaN (missing)\n",
        "        if pd.isna(value):\n",
        "            return 0.0\n",
        "        # Remove '$', ',', and spaces. Some numbers might be in parentheses for negative.\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip().replace('(', '-').replace(')', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except ValueError:\n",
        "            # If conversion fails, return 0.0 or log an error\n",
        "            return 0.0\n",
        "\n",
        "    df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "    print(\"‚úÖ Money values standardized.\")\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    # Added .fillna('') to handle potential NaN values in 'Title'\n",
        "    vague_data = df[df['Title'].fillna('').str.lower() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    # Only show if there are actual vague contracts\n",
        "    if not vague_data.empty:\n",
        "        print(vague_data[['Agency', 'Title', 'Value (AUD)']].head())\n",
        "    else:\n",
        "        print(\"No vague contracts found in this sample.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwMW3LIgs48E",
        "outputId": "8a08b042-0665-4ec2-d635-910dfc5f2f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Data loaded correctly.\n",
            "Total rows found: 49\n",
            "Columns found: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n",
            "\n",
            "First 5 rows of actual data (including headers):\n",
            "     Unnamed: 0                                         Unnamed: 1  \\\n",
            "0         CN ID                                              Title   \n",
            "1  CN3820600-A2  Project Assurance Services for the Schools Uni...   \n",
            "2     CN3922991                       Management advisory services   \n",
            "3     CN3903240  Payroll voluntary redundancy advisory services...   \n",
            "4     CN3900356              Supplier Accreditation System Support   \n",
            "\n",
            "                                          Unnamed: 2    Unnamed: 3  \\\n",
            "0                                             Agency  Publish Date   \n",
            "1                            Department of Education     15-Oct-21   \n",
            "2  Office of the Official Secretary to the Govern...      8-Nov-22   \n",
            "3    Australian Building and Construction Commission      8-Aug-22   \n",
            "4                              Department of Defence     28-Jul-22   \n",
            "\n",
            "                     Unnamed: 4           Unnamed: 5      Unnamed: 6  \\\n",
            "0                      Category  Contract Start Date  Execution Date   \n",
            "1  Management advisory services             1-Oct-21             NaN   \n",
            "2  Management advisory services            24-Oct-22             NaN   \n",
            "3  Management advisory services            29-Jul-22             NaN   \n",
            "4  Management advisory services             1-Aug-22             NaN   \n",
            "\n",
            "          Unnamed: 7    Unnamed: 8  Unnamed: 9  \\\n",
            "0  Contract End Date   Value (AUD)      ATM ID   \n",
            "1           2-Oct-23  2,704,622.80  RFT 5-2018   \n",
            "2          30-Jun-23     75,000.00   CON000742   \n",
            "3          31-Oct-22    151,470.00         NaN   \n",
            "4          31-Dec-22     60,000.00         NaN   \n",
            "\n",
            "                                         Unnamed: 10         Unnamed: 11  \\\n",
            "0                                      Supplier Name        Last Updated   \n",
            "1                                                PWC   06-Jan-23 4:01 pm   \n",
            "2  PwC PricewaterhouseCoopers Consulting (Austral...  08-Nov-22 11:33 am   \n",
            "3                       PWC - PRICEWATERHOUSECOOPERS   08-Aug-22 4:04 pm   \n",
            "4                         PWC CONSULTING PTY LIMITED   28-Jul-22 1:55 pm   \n",
            "\n",
            "   Unnamed: 12  \n",
            "0          NaN  \n",
            "1          NaN  \n",
            "2          NaN  \n",
            "3          NaN  \n",
            "4          NaN  \n",
            "\n",
            "‚ö†Ô∏è Still didn't find the expected column names. Adjust 'skiprows' or check your CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PACE MODULE 1 (V2): DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. LOAD THE DATA with SKIPPING\n",
        "# We use 'skiprows' to jump over the \"Criteria Summary\" section at the top.\n",
        "# If this doesn't work, we might need to change 14 to 15 or 16.\n",
        "try:\n",
        "    # Try skipping 14 rows first (common for AusTender)\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1', skiprows=14)\n",
        "\n",
        "    # Double check if we hit the right header row by looking for \"Supplier Name\"\n",
        "    if 'Supplier Name' not in df.columns:\n",
        "        # If not, try reloading with 15 rows skipped (sometimes it varies by 1 line)\n",
        "        df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1', skiprows=15)\n",
        "\n",
        "    print(\"‚úÖ Success! Data loaded correctly.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "    print(\"Columns found:\", list(df.columns)) # Printing this to be sure\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "\n",
        "# Only proceed if we actually have the data loaded with correct headers\n",
        "if 'Supplier Name' in df.columns:\n",
        "\n",
        "    # 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "    def clean_supplier_name(name):\n",
        "        name_str = str(name).upper()\n",
        "        if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "            return 'PwC (Consolidated)'\n",
        "        else:\n",
        "            return name\n",
        "\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    def clean_money(value):\n",
        "        # Remove '$' and ',' and spaces\n",
        "        clean_val = str(value).replace('$', '').replace(',', '').strip()\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "    print(\"‚úÖ Money values standardized.\")\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    vague_data = df[df['Title'].str.lower() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Still didn't find 'Supplier Name'. Check the skiprows number.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrwbkAoBsn1K",
        "outputId": "3ebe27e9-7fa6-4cb7-f035-2ea9ef9ebbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Data loaded correctly.\n",
            "Total rows found: 50\n",
            "Columns found: ['Consultancy?', 'All', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n",
            "\n",
            "‚ö†Ô∏è Still didn't find 'Supplier Name'. Check the skiprows number.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data again\n",
        "df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Print the list of column names\n",
        "print(\"Here are the EXACT column names in your file:\")\n",
        "print(list(df.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTbqZaI7saAY",
        "outputId": "ed63958e-87e1-4d9e-b16e-8664ef9223c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the EXACT column names in your file:\n",
            "['Contract Notice List', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "axxfQ0gNq-O0",
        "outputId": "71647e41-0622-43fc-b9c9-64f29445ce33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Data loaded.\n",
            "Total rows found: 65\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Supplier Name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Supplier Name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3054264818.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Apply this logic to a new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'df'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Only run if data loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clean_Supplier'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Supplier Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_supplier_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Supplier names standardized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Supplier Name'"
          ]
        }
      ],
      "source": [
        "# --- PACE MODULE 1: DATA INGESTION & CLEANING ---\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# 1. LOAD THE DATA\n",
        "# We are telling Python to read the CSV file you uploaded.\n",
        "# Note: 'encoding' handles special characters often found in gov data.\n",
        "try:\n",
        "    df = pd.read_csv('pace_data.csv', encoding='ISO-8859-1')\n",
        "    print(\"‚úÖ Success! Data loaded.\")\n",
        "    print(f\"Total rows found: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: Could not find 'pace_data.csv'. Did you upload it to the folder on the left?\")\n",
        "\n",
        "# 2. CLEAN THE SUPPLIER NAMES (The \"PwC\" Fix)\n",
        "def clean_supplier_name(name):\n",
        "    # Make sure the name is text (string) and make it uppercase\n",
        "    name_str = str(name).upper()\n",
        "\n",
        "    # The Logic: If it sounds like PwC, make it \"PwC (Consolidated)\"\n",
        "    if 'PWC' in name_str or 'PRICEWATERHOUSE' in name_str:\n",
        "        return 'PwC (Consolidated)'\n",
        "    # We can add Deloitte/KPMG later\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "# Apply this logic to a new column\n",
        "if 'df' in locals(): # Only run if data loaded\n",
        "    df['Clean_Supplier'] = df['Supplier Name'].apply(clean_supplier_name)\n",
        "    print(\"‚úÖ Supplier names standardized.\")\n",
        "\n",
        "    # 3. CLEAN THE MONEY COLUMN\n",
        "    # Excel money often looks like \"$2,500.00\". Computers hate the '$' and ','.\n",
        "    # We need to turn it into a pure number.\n",
        "    def clean_money(value):\n",
        "        clean_val = str(value).replace('$', '').replace(',', '')\n",
        "        try:\n",
        "            return float(clean_val)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    df['Clean_Value'] = df['Value (AUD)'].apply(clean_money)\n",
        "    print(\"‚úÖ Money values standardized.\")\n",
        "\n",
        "    # --- PACE MODULE 2: BASIC ANALYSIS ---\n",
        "\n",
        "    # Analysis A: Total Spend by the Consolidated PwC Entity\n",
        "    pwc_data = df[df['Clean_Supplier'] == 'PwC (Consolidated)']\n",
        "    total_pwc = pwc_data['Clean_Value'].sum()\n",
        "\n",
        "    # Analysis B: The \"Vague Description\" Hunter\n",
        "    # Looking for titles exactly matching \"Management advisory services\"\n",
        "    vague_data = df[df['Title'].str.lower() == 'management advisory services']\n",
        "    total_vague = vague_data['Clean_Value'].sum()\n",
        "    vague_count = len(vague_data)\n",
        "\n",
        "    # --- REPORTING ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"      PACE ENGINE - INITIAL REPORT      \")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üí∞ Total Spend with PwC (Consolidated): ${total_pwc:,.2f}\")\n",
        "    print(f\"üå´Ô∏è  Contracts with Vague Descriptions:   {vague_count}\")\n",
        "    print(f\"üí∏ Total Value of Vague Contracts:      ${total_vague:,.2f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Optional: Show the first few vague rows to prove it works\n",
        "    print(\"\\nSample of Vague Contracts Found:\")\n",
        "    print(vague_data[['Agency', 'Title', 'Value (AUD)']].head())\n"
      ]
    }
  ]
}